import os
import faiss
import numpy as np
from pypdf import PdfReader
from sentence_transformers import SentenceTransformer

# ---------- CONFIG ----------
DOCS_FOLDER = "Docs"
CHUNK_SIZE = 800
CHUNK_OVERLAP = 100
TOP_K = 6
# ---------------------------

model = SentenceTransformer("all-MiniLM-L6-v2")

# 1. Load & clean PDFs
def load_documents(folder):
    texts = []
    for file in os.listdir(folder):
        if file.endswith(".pdf"):
            reader = PdfReader(os.path.join(folder, file))
            for page in reader.pages:
                text = page.extract_text()
                if text:
                    text = text.replace("\n", " ")
                    text = " ".join(text.split())
                    texts.append(text)
    return texts

# 2. Chunk text
def chunk_text(texts):
    chunks = []
    for text in texts:
        start = 0
        while start < len(text):
            end = start + CHUNK_SIZE
            chunks.append(text[start:end])
            start = end - CHUNK_OVERLAP
    return chunks

# 3. Create embeddings
def embed_texts(texts):
    embeddings = model.encode(texts, show_progress_bar=True)
    return np.array(embeddings).astype("float32")

# 4. Build FAISS index
def build_index(vectors):
    index = faiss.IndexFlatL2(vectors.shape[1])
    index.add(vectors)
    return index

# 5. FINAL Answer logic (question-aware)
def answer_question(question, index, chunks):
    q_lower = question.lower()

    # Explicit handling for overview / objective questions
    if "what is this document about" in q_lower or "objective of the document" in q_lower:
        return f"""
Question:
{question}

Answer:
This document is a Student Information Book for the PGDM programme (2025â€“26) at SDMIMD. 
It serves as a comprehensive guide for students by explaining the academic structure, 
rules and regulations, evaluation methods, code of conduct, disciplinary policies, 
projects, and general institutional information required during the programme.

(This answer is generated by combining semantic retrieval with structured interpretation.)
"""

    # Retrieval-based answers for other questions
    q_vector = embed_texts([question])
    _, idx = index.search(q_vector, TOP_K)

    retrieved_chunks = [chunks[i] for i in idx[0]]
    all_text = " ".join(retrieved_chunks)

    sentences = all_text.split(". ")
    filtered = [s.strip() for s in sentences if len(s.strip()) > 60]

    summary = ". ".join(filtered[:5])

    return f"""
Question:
{question}

Answer:
{summary}

(This answer is generated using semantic retrieval and rule-based summarization.)
"""

# ---------- PIPELINE ----------
print("Loading documents...")
documents = load_documents(DOCS_FOLDER)
print(f"Loaded {len(documents)} pages")

print("Chunking text...")
chunks = chunk_text(documents)
print(f"Created {len(chunks)} chunks")

print("Creating embeddings (local model)...")
vectors = embed_texts(chunks)

print("Building vector index...")
index = build_index(vectors)

print("\nSystem ready. Ask questions.\n")

while True:
    q = input("Ask a question (type 'exit' to quit): ")
    if q.lower() == "exit":
        break
    answer = answer_question(q, index, chunks)
    print(answer)
    print("\n" + "-" * 60 + "\n")


